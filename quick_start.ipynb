{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first Jupyter Notebook on FloydHub\n",
    "\n",
    "This tutorial introduces FloydHub and how to use Jupyter Notebooks for your experiments.\n",
    "\n",
    "### Here’s what we’ll learn in this guide:\n",
    "\n",
    "- How to use Jupyter Notebooks on FloydHub\n",
    "- How to Create, Explore, and Mount datasets on FloydHub to use in your code\n",
    "- FloydHub best practices:\n",
    " 1. How and why to keep datasets separate from code as standalone Datasets\n",
    " 2. How to sync your remote FloydHub experiments locally to your machine\n",
    " 3. How to use .floydignore for low-bandwidth situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Jupyter Notebook\n",
    "\n",
    "[Jupyter Notebooks](https://jupyter.org/) are great for interactively writing, running and sharing your code right in your browser. A notebook, like this one, is made up of Cells, which can either be Code Cells or Markdown Cells. The most important thing to learn is the **`shift + enter`** shortcut, which runs any command in a Code Cell. \n",
    "\n",
    "Try it now on the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Hello FloydHub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using FloydHub datasets in your code\n",
    "\n",
    "Now, let's go through some simple examples to learn how use public datasets in your Jupyter Notebooks on  FloydHub.\n",
    "\n",
    "### a. Download & explore a dataset\n",
    "\n",
    "Let’s take a public [url](https://raw.githubusercontent.com/plotly/datasets/master/2011_us_ag_exports.csv) of a csv dataset (2011 US Agriculture Exports by State) and create a plot chart of the [United States Choropleth Map](https://plot.ly/python/choropleth-maps/) graph using [Plotly](https://github.com/plotly/plotly.py) inside our Jupyter Noteook.\n",
    "\n",
    "By default, we don’t have the plotly package installed on this instance (although FloydHub does automatically include lots of great libraries like [Numpy](http://www.numpy.org/), [Pandas](http://pandas.pydata.org/) and [Matplotlib](https://matplotlib.org/). \n",
    "\n",
    "But, don’t worry, we have two options for adding plotly to our FloydHub Jupyter Notebook instance:\n",
    "\n",
    "1.**Install the package through the Juypter terminal.**  Just type `!` at the beginning of a Code cell to run a shell command, where we can install plotly. Note that you can list the [Jupyter Magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) with the `% lsmagic` command. In this way you can extend your notebook with more functionalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.**Declare the dependencies inside the floyd_requirements.txt file and relaunch the Jupyter instance.** This is the best practice when you already know the dependencies that code requires. Just add a text file called `floyd_requirements.txt` in your project repository and add the line: `plotly` as done by the code snippet just below. FloydHub *will download all the python dependencies* inside this file during the creation of your job’s environment.\n",
    "\n",
    "\n",
    "Note:\n",
    "\n",
    "1. This work only for Python dependencies. For Non-python dependencies you have to run a bash command pipeline see docs for more info: [installing-non-python-dependencies](https://docs.floydhub.com/guides/jobs/installing_dependencies/#installing-non-python-dependencies).\n",
    "2. `floyd_requirements.txt` is only used during the creation of a job instance, so you’ll need to recreate your instance with the floyd restart command or by clicking the Restart button on your dashboa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! touch floyd_requirements.txt && echo plotly > floyd_requirements.txt # if you want to append more lines use >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat floyd_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have to `Restart` your Job. To do this [Stop](https://docs.floydhub.com/guides/stop_job/) the current Job and [Restart](https://docs.floydhub.com/guides/restart_job/) it from the Web Dashboard or CLI.\n",
    "\n",
    "To a more detailed reference see [Install Extra Dependencies](https://docs.floydhub.com/guides/jobs/installing_dependencies/) from our docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to explore our dataset, but before run any commands, it's a good practice to keep a unique cell with all the package declaration we need - this improves code maintainability a lot! What’s great is that the dependencies will persist into the subsequent cells, so `plotly` and `pandas` will be available in future code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import pandas as pd\n",
    "\n",
    "print (__version__) # requires version >= 1.9.0 to use Offline mode\n",
    "\n",
    "# This allow us to plot our graphs offline inside a Jupyter Notebook Environment\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to plot United States [Choropleth Map](https://en.wikipedia.org/wiki/Choropleth_map) graph about Agriculture Exports by State during 2011. (Now just press the **`Shift + Enter`** command in the Code cell below to create your Chart.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2011_us_ag_exports.csv')\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n",
    "            [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n",
    "\n",
    "df['text'] = df['state'] + '<br>' +\\\n",
    "    'Beef '+df['beef']+' Dairy '+df['dairy']+'<br>'+\\\n",
    "    'Fruits '+df['total fruits']+' Veggies ' + df['total veggies']+'<br>'+\\\n",
    "    'Wheat '+df['wheat']+' Corn '+df['corn']\n",
    "\n",
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = df['code'],\n",
    "        z = df['total exports'].astype(float),\n",
    "        locationmode = 'USA-states',\n",
    "        text = df['text'],\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"Millions USD\")\n",
    "        ) ]\n",
    "\n",
    "layout = dict(\n",
    "        title = '2011 US Agriculture Exports by State<br>(Hover for breakdown)',\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            lakecolor = 'rgb(255, 255, 255)'),\n",
    "             )\n",
    "    \n",
    "fig = dict( data=data, layout=layout )\n",
    "iplot( fig, filename='d3-cloropleth-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![map](d3-cloropleth-map.png)\n",
    "\n",
    "*Your chart should look like this image!*\n",
    "\n",
    "Having a proper way to visualize experiments is one of the most important aspect of every Data Scientists workflow and a great way to debug code. If you are more interested in a ML workflow you can take a look at [MNIST Notebook tutorial](https://docs.floydhub.com/getstarted/get_started_jupyter/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Creating a FloydHub dataset\n",
    "\n",
    "\n",
    "fter you’ve done the work to clean and transform a dataset inside a Notebook, it’s a very common practice to save this data as a separate [Dataset](https://docs.floydhub.com/guides/create_and_upload_dataset/) on FloydHub. This will let you easily mount your data inside future jobs - and you won’t have to repeat yourself. Using FloydHub to manage your data also helps you speed up your workflow because you won’t need to redownload the data multiple times.\n",
    "Let’s try it out in our current notebook!\n",
    "\n",
    "\n",
    "#### Downloading COCO Dataset\n",
    "\n",
    "[COCO - Common Object in Context](http://cocodataset.org/#home) is a famous dataset widely adopted for Detection, Keypoint and Stuff Segmentation(from this year) Challenges. Let's take the 2014 Train images dataset which is around 13 GB and upload it as FloydHub dataset in a few minutes. \n",
    "\n",
    "**Note: FloydHub instances have a max storage of 100GB, so make sure to not overcome this size when downloading, process or create a dataset.**\n",
    "\n",
    "Our CPU instance should have a 50 MB/s in download, so it should take around 3 minutes on Download, Compressing data Time: about 10', Uploading Time: about 12'(15 MB/s in upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://images.cocodataset.org/zips/train2014.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the file is in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the dataset and remove the zipped version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip train2014.zip && rm train2014.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we have downloaded/created is ready to be imported as FloydHub dataset with a *New* feature: Dataset acquisition from Job's Output! Suddenly after you have Stopped the Jobs, you can create a dataset from the output through Web Dashboard or CLI. - SEE MORE ON ...\n",
    "\n",
    "Now you’ve got a separate Dataset that you can use in future jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mount datasets or Previuos Job Output\n",
    "\n",
    "This is pretty straightforward, just follow our great docs: [Mounting Data](https://docs.floydhub.com/guides/data/mounting_data/).\n",
    "\n",
    "**Note about output**: To retrieve the **Output** of your Job you have to save the artefatcs returned by your experiments in the `/output` folder and make sure the your script/programs are compliant with this policy, otherwise the output of your Jobs will be empty. Jupyter Notebook default working directory is `/output` folder so you do not have to worry about this when you run your Jobs in `--mode jupyter`. For more, see [Save Output](https://docs.floydhub.com/guides/data/storing_output/) in our docs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FloydHub Best Practices\n",
    "\n",
    "If you have follow this tutorial, you have certainly noticed that we have worked only on a FloydHub remote Job and the code we have locally is not sync/outdate/not update.\n",
    "\n",
    "To update everything locally we can dowload everything from the Output tab of the Job's Overview of the Web Dashboard or using the CLI with `floyd data clone <output>`, see more on [output download](https://docs.floydhub.com/guides/download_output/) on our docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Keeping code separate from data\n",
    "\n",
    "The Keypoint of your experiments and a Data Science best pratice is to have a clean separation of the code from the data that it uses. This will allow you to structure the experiments/Jobs in a more elegant way and optimize the code you need to upload on FloydHub and speed up the experiment cycle iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Sync your remote experiments locally\n",
    "\n",
    "If you have follow this tutorial, you have certainly noticed that we have worked only on a FloydHub remote Job and the code we have locally is not synced with the current state of our Jupyter Notebook.\n",
    "\n",
    "If you’d like to update everything locally, we can download everything from the Output tab of the Job's Overview of the Web Dashboard or by using the CLI with `floyd data clone <output>`.\n",
    "\n",
    "You can read more on [output download](https://docs.floydhub.com/guides/download_output/) on our docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.  Using .floydignore\n",
    "\n",
    "Use `.floydignore` will can speed up your upload and experiments iterations if your project code contains items that can be ignored from experiments code’s point of view (such as docs, images and video). See our FAQ about [long sync](https://docs.floydhub.com/faqs/job/#my-job-is-taking-a-while-to-sync-changes-how-do-i-make-it-go-faster).\n",
    "\n",
    "**Note**: If your internet connection have a low bandwidth in upload, with this file you can really improve your experience on our service.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
