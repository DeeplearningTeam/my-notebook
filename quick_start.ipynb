{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Jupyter Notebooks on FloydHub\n",
    "\n",
    "[Jupyter Notebooks](https://jupyter.org/) are great for interactively writing, running and sharing your code right from your browser. This tutorial teaches you the basics of running GPU-powered Notebooks on FloydHub.\n",
    "\n",
    "Running a Jupyter Notebook on FloydHub is easy. Simply type this on your terminal:\n",
    "```\n",
    "floyd run --mode jupyter --gpu\n",
    "```\n",
    "This will open a Jupyter Notebook with GPU support, running on FloydHub's servers. If you're viewing this Notebook on FloydHub, you probably already did that! For more info, here's a [quick start tutorial](https://docs.floydhub.com/getstarted/quick_start_jupyter/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU and GPU Support\n",
    "\n",
    "Notice the `--gpu` flag in the above command? That's all you need to do to get access to a powerful GPU in the cloud. You can view the stats and usage of your GPU by executing the command in the cell below (press **`shift + enter`**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you will see the GPU stats only if you use the `--gpu` flag in your `floyd run` command. You can run your Notebook on a CPU machine by omitting the flag or using `--cpu`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Environments\n",
    "\n",
    "FloydHub comes with fully-configured and optimized environments for all deep learning frameworks! So, you don't have to fiddle with installing CUDA drivers, the framework(s) of your choice and all their dependencies.\n",
    "\n",
    "The default environment is the latest version of Tensorflow and Keras. Go ahead and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__name__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__name__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use a different framework, you can specify this using the `--env` flag when you start your Notebook. Want a PyTorch Notebook? Start your Notebook with the following command from your local terminal\n",
    "```\n",
    "floyd run --mode jupyter --gpu --env pytorch-0.2\n",
    "```\n",
    "You can see the complete list of deep learning environments [here](https://docs.floydhub.com/guides/environments/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies\n",
    "\n",
    "All the environments also include lots of common machine learning and deep learning libraries like [Numpy](http://www.numpy.org/), [Pandas](http://pandas.pydata.org/) and [Matplotlib](https://matplotlib.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(15).reshape(3, 5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we might not have all the packages you want. You can install your own packages from inside your Notebook! Let's install the `plotly` Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have more involved requirements - we got you covered!\n",
    "\n",
    "Say, you want to install multiple Python packages. See how to use [floyd_requirements.txt](https://docs.floydhub.com/guides/jobs/installing_dependencies/#installing-python-dependencies).\n",
    "\n",
    "Or, your dependency isn't a Python package at all and you want to install it via `apt-get` or even compile it from source. Take a look at our in-depth guide on [installing extra dependencies](https://docs.floydhub.com/guides/jobs/installing_dependencies/#installing-non-python-dependencies)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model for handwritten digit recognition\n",
    "\n",
    "MNIST is a simple computer vision dataset of handwritten digits like these:\n",
    "<img src=\"https://www.tensorflow.org/images/MNIST.png\" width=\"300\"/>\n",
    "Owing to its popularity, it is commonly called the \"Hello World\" of machine learning! You can read more about it in the [Tensorflow's tutorial](https://www.tensorflow.org/get_started/mnist/beginners).\n",
    "\n",
    "We will now train a simple multilayer perceptron model to recognize the handwritten digits using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "batch_size = 128\n",
    "nb_epoch = 10\n",
    "\n",
    "# Parameters for MNIST dataset\n",
    "nb_classes = 10\n",
    "\n",
    "# Parameters for MLP\n",
    "prob_drop_input = 0.2               # drop probability for dropout @ input layer\n",
    "prob_drop_hidden = 0.5              # drop probability for dropout @ fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from the internet (https://s3.amazonaws.com/img-datasets/mnist.npz)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Split the dataset into a training set and test set\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_Train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_Test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multilayer Perceptron model\n",
    "model = Sequential()\n",
    "model.add(Dense(activation=\"sigmoid\", units=625, input_dim=784, kernel_initializer=\"normal\", name=\"dense1\"))\n",
    "model.add(Dropout(prob_drop_input, name='dropout1'))\n",
    "model.add(Dense(activation=\"sigmoid\", units=625, input_dim=625, kernel_initializer=\"normal\", name=\"dense2\"))\n",
    "model.add(Dropout(prob_drop_hidden, name='dropout2'))\n",
    "model.add(Dense(activation=\"softmax\", units=10, input_dim=625, kernel_initializer=\"normal\", name=\"dense3\"))\n",
    "model.compile(optimizer=RMSprop(lr=0.001, rho=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define directories to save the model checkpoints and logs\n",
    "save_model(model, '/output/model_mlp')\n",
    "!mkdir -p /output/logs\n",
    "checkpoint = ModelCheckpoint(filepath='/output/logs/weights.epoch.{epoch:02d}-val_loss.{val_loss:.2f}.hdf5', verbose=0)\n",
    "\n",
    "# Start training model\n",
    "history = model.fit(X_train, Y_Train, epochs=nb_epoch, batch_size=batch_size, verbose=1,\n",
    "                    callbacks=[checkpoint], validation_data=(X_test, Y_Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained our model for 10 epochs. At the end of the 10th epoch, our accuracy on the holdout validation set is around 97%. Not bad!\n",
    "\n",
    "Now, let's test our model on the Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluation = model.evaluate(X_test, Y_Test, verbose=1)\n",
    "print('\\nSummary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it folks! You learnt some of the basics of using Jupyter Notebook on FloydHub and trained a pretty sleek model to recognize handwritten digits. Feel free to play around! (and don't forget to shutdown your job)\n",
    "\n",
    "Below, we'll talk about slightly more advanced FloydHub constructs. \n",
    "\n",
    "* How do you save your data so you can come back later and use it? \n",
    "* How do you find and use others' public datasets in your job?\n",
    "* How do I restart my old Notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Output Data on FloydHub\n",
    "\n",
    "We just trained a model that recognizes handwritten digits with a 98% accuracy! We, of course, want to save the model that we trained so we can utilize it later.\n",
    "\n",
    "If you look at the code above, you will notice that the model checkpoints and logs are stored under `/output/model_mlp` and `/output/logs` respectively.\n",
    "```\n",
    "save_model(model, '/output/model_mlp')\n",
    "!mkdir -p /output/logs\n",
    "checkpoint = ModelCheckpoint(filepath='/output/logs/weights.epoch.{epoch:02d}-val_loss.{val_loss:.2f}.hdf5', verbose=0)\n",
    "```\n",
    "\n",
    "**The `/output` directory is a special directory on FloydHub.** Any directories, subdirectories or files that you create under the `/output` directory will be saved for you to use later, even after you close your Jupyter Notebook. \n",
    "\n",
    "**tl;dr: Please ensure that any data that you want to persist should be saved under `/output`. Data stored in any other location will be deleted when you end your Jupyter Notebook job.** Please see our extensive guide on [saving persistant outputs on FloydHub](https://docs.floydhub.com/guides/data/storing_output/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FloydHub's Public Datasets in your Jobs\n",
    "\n",
    "FloydHub has a ton of popular datasets. These are community contributed datasets for many machine learning and deep learning tasks. You can find them in the [Explore Page](https://www.floydhub.com/explore/trending) or using the [Search box](https://www.floydhub.com/search/datasets?query=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we downloaded the MNIST dataset from the internet using this line of code:\n",
    "```\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "```\n",
    "This works well because the MNIST dataset is only about 11MB. If you had a larger dataset, it'd be a pain to download it every time. We highly recommend [creating a separate dataset](https://docs.floydhub.com/guides/create_and_upload_dataset/) or using a publicly available dataset. Here's a public MNIST dataset on FloydHub: [https://www.floydhub.com/redeipirati/datasets/mnist](https://www.floydhub.com/redeipirati/datasets/mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a public dataset in your job, you need to _mount_ it when you execute your `floyd run` command:\n",
    "```\n",
    "floyd run --mode jupyter --gpu --data redeipirati/datasets/mnist/1:mnist\n",
    "```\n",
    "This will make this dataset available at `/mnist` for your code to access. You can read more about mounting datasets in our [docs here](https://docs.floydhub.com/guides/data/mounting_data/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Stopping your Notebook\n",
    "\n",
    "You can save the progress you've made in your Notebook by clicking `File -> Save and Checkpoint`. You can view your saved Notebook from the `Code` tab of your job.\n",
    "\n",
    "Here's [an example](https://www.floydhub.com/emilwallner/projects/deep-learning-from-scratch/3/code/MNIST_deep_learning.ipynb).\n",
    "\n",
    "**Once you're done working on your Notebook, don't forget to shutdown your job!** You can shutdown your job by clicking on `Cancel` in your job's dashboard. Here's [our guide](https://docs.floydhub.com/guides/stop_job/).\n",
    "\n",
    "<img src=\"https://docs.floydhub.com/img/stop_job.jpg\" width=\"500\"/>\n",
    "\n",
    "**Note that simply closing the Notebook tab does not shutdown the job.** Since Jupyter Notebooks are interactive development environments, we don't know if you're done for the day or if you're going to come back and continue working on your Notebook. So, we'll keep your your Notebook running (and charge you) till you explicitly shut it down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restarting your Notebook\n",
    "\n",
    "You can also restart your Notebook to continue working from where you left off by clicking on the `Restart` button. Here's the [guide for it](https://docs.floydhub.com/guides/restart_job/).\n",
    "\n",
    "<img src=\"https://docs.floydhub.com/img/restart_jupyter.gif\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FloydHub Best Practices\n",
    "\n",
    "### a. Keeping code separate from data\n",
    "\n",
    "A keypoint of your experiments and a data science best pratice is to have a clean separation of the code from the data that it uses. This will allow you to structure the experiments/Jobs in a more elegant way and optimize the code you need to upload on FloydHub and speed up the experiment cycle iterations.\n",
    "\n",
    "### b. Sync your remote experiments locally\n",
    "\n",
    "If you have followed this tutorial, you have certainly noticed that we have worked only on a FloydHub remote Job and the code we have locally is not synced with the current state of our Jupyter Notebook.\n",
    "\n",
    "If you’d like to update everything locally, we can download everything from the Output tab of the Job's Overview of the Web Dashboard or by using the CLI with `floyd data clone <output>`.\n",
    "\n",
    "You can read more on [output download](https://docs.floydhub.com/guides/download_output/) on our docs.\n",
    "\n",
    "### c.  Using .floydignore\n",
    "\n",
    "Use `.floydignore` will can speed up your upload and experiments iterations if your project code contains items that can be ignored from experiments code’s point of view (such as docs, images and video). See our FAQ about [long sync](https://docs.floydhub.com/faqs/job/#my-job-is-taking-a-while-to-sync-changes-how-do-i-make-it-go-faster).\n",
    "\n",
    "**Note**: If your internet connection have a low bandwidth in upload, with this file you can really improve your experience on our service."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
